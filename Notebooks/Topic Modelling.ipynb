{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Topic Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/tomewing/anaconda/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/Users/tomewing/anaconda/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/Users/tomewing/anaconda/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/Users/tomewing/anaconda/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/Users/tomewing/anaconda/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n",
      "/Users/tomewing/anaconda/lib/python3.5/site-packages/funcy/decorators.py:56: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  spec = inspect.getargspec(func)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "import pyLDAvis.gensim\n",
    "import warnings\n",
    "\n",
    "from gensim import corpora, models\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "warnings.filterwarnings('ignore', category=DeprecationWarning, message='.*use @default decorator instead.*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))       # Changing the cell widths\n",
    "\n",
    "pd.options.display.max_rows = 30                                            # Setting the max number of rows\n",
    "pd.options.display.max_columns = 50                                         # Setting the max number of columns\n",
    "\n",
    "pyLDAvis.enable_notebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = '/Users/tomewing/Datadive/Data/'    # Data Directory \n",
    "out = '/Users/tomewing/Datadive/Datadive/Outputs/'  # Output Directory\n",
    "msg = 'messages.csv'                       # Input Dataset\n",
    "\n",
    "sample_size = 5000\n",
    "topics = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_msg_in = pd.read_csv(path + msg)\n",
    "df_msg_en = df_msg_in[(df_msg_in['language'] == 'EN')] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def cleaner(row):\n",
    "    '''Function to clean the text data and prep for further analysis'''\n",
    "    text = row['body'].lower()                   # Converts to lower case\n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text)          # Removes punctuation\n",
    "    text = re.sub(\"cyclist\",\"cycl\",text)         # Manual intervention for 'cyclist'\n",
    "    text = text.split()                          # Splits the data into individual words \n",
    "    text = [w for w in text if not w in stops]   # Removes stopwords\n",
    "    text = [p_stemmer.stem(i) for i in text]     # Stemming (reducing words to their root)\n",
    "    return text\n",
    "\n",
    "def model(data):\n",
    "    stops = set(stopwords.words(\"english\"))     # Creating a set of Stopwords\n",
    "    p_stemmer = PorterStemmer()                 # Creating the stemmer model\n",
    "    data_dict = corpora.Dictionary(data)                       # Creates an id <-> term dictionary\n",
    "    data_corpus = [data_dict.doc2bow(text) for text in data]     # convert tokenized documents into a document-term matrix\n",
    "    data_model = gensim.models.ldamodel.LdaModel(data_corpus, \n",
    "                                                   num_topics=topics, \n",
    "                                                   id2word = data_dict,\n",
    "                                                   passes=20)        #  generate LDA model\n",
    "\n",
    "    data_vis = pyLDAvis.gensim.prepare(data_model, data_corpus, data_dict)        # Visualise LDA Model\n",
    "    pyLDAvis.save_html(data=data_vis,\n",
    "                       fileobj=out + 'Data_vis.html')\n",
    "    data_vis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_msg_en['Clean'] = df_msg_en.apply(cleaner,axis=1)\n",
    "\n",
    "df_msg_en_q = df_msg_en[(df_msg_en['type'] == 'Q')]\n",
    "df_msg_en_a = df_msg_en[(df_msg_en['type'] == 'A')]\n",
    "\n",
    "li_msg_en_q = df_msg_en_q['Clean'].tolist()\n",
    "li_msg_en_a = df_msg_en_a['Clean'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sample = li_msg_en_q[:sample_size]\n",
    "model(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
